{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1bslYAz5kSdbjxBr5EtOXz6lbOhhf3nii",
      "authorship_tag": "ABX9TyNDprIvFcvtz6dxRA9YA4QN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/mnist-digit-recognition/blob/master/recognise_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Recognition\n",
        "\n",
        "Deep Learning model for Handwritten Digit Recognition using TensorFlow and Neural Network Techniques\n",
        "\n",
        "## 1. Problem Definition â›‘\n",
        "\n",
        "Recognise handwritten digit, from a dataset which contains B&W images of each digit written on 28x28 pixel box.\n",
        "\n",
        "## 2. Data \n",
        "\n",
        "The data we're using is officially provided by [The MNIST DATABASE](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "The digits have been sized-normalized and centered in a fixed-sized image.\n",
        "\n",
        "The data is quite preprocessed and well-formatted.\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "Test Error Rate(%) should be lower than 1.0\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data,\n",
        "* We're dealing with images(unstructured data) so it's probably best we use deep learning/transfer learning technique to solve this problem.\n",
        "* There are around a 60,000 examples of training set. \n",
        "* There are around a 10,000 examples of test set."
      ],
      "metadata": {
        "id": "O7o-vJCUoMr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Workspace ready !\n",
        "\n",
        "* Import Tensorflow\n",
        "* Import Tensorflow hub\n",
        "* Check if GPU is running or not"
      ],
      "metadata": {
        "id": "oAfdV77pFsDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "_BIXOY5lq_NE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb3d4ad-ef86-4b40-cef8-1a3164d82e48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow hub\n",
        "import tensorflow_hub as hub\n",
        "print(hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci5xx0QgFe4I",
        "outputId": "4cacff62-efe9-4444-ef8a-cdb676c6328d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU availibility\n",
        "print(\"GPU\", \"available (YES !!!!!!)\"if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yern88eF5dX",
        "outputId": "30ea8e08-cbb2-49a9-d38d-1e3064f147e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available (YES !!!!!!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready\n",
        "\n",
        "I've manually downloaded the data from MNIST database, and uploaded into my Google drive.\n",
        "\n",
        "### Load the data\n",
        "\n",
        "We have the data in gzip and IDX format so have to un-gzip the files and then read the IDX file using numpy. "
      ],
      "metadata": {
        "id": "5BNIeOKtHem7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iKgbFwzSIyIW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to read the mnist data\n",
        "def read_mnist(images_path: str, labels_path:str):\n",
        "  with gzip.open(labels_path,'rb') as labelsFile:\n",
        "    labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
        "  with gzip.open(images_path, 'rb') as imagesFile:\n",
        "    length = len(labels)\n",
        "    # Load flat 28x28 px images (784px), and convert them to 28x28 px\n",
        "    features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
        "                   .reshape(length, 784) \\\n",
        "                   .reshape(length, 28, 28, 1)\n",
        "  return features, labels"
      ],
      "metadata": {
        "id": "UrtVG0cWMwci"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = {}\n",
        "test = {}\n",
        "\n",
        "train['features'], train['labels'] = read_mnist('drive/MyDrive/Data Science/MNIST Handwritten Digits/data/train-images-idx3-ubyte.gz', \n",
        "                                                'drive/MyDrive/Data Science/MNIST Handwritten Digits/data/train-labels-idx1-ubyte.gz')\n",
        "\n",
        "test['features'], test['labels'] = read_mnist('drive/MyDrive/Data Science/MNIST Handwritten Digits/data/t10k-images-idx3-ubyte.gz',\n",
        "                                              'drive/MyDrive/Data Science/MNIST Handwritten Digits/data/t10k-labels-idx1-ubyte.gz')"
      ],
      "metadata": {
        "id": "H_cBnMOIN_tL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the data\n",
        "\n",
        "Before going further and jumping directly to any step, exploring the data will help us to decide what are the things we need to do with our data,\n",
        "* Find outliers\n",
        "* If we need a preprocessing phase to uniform\n",
        "* Check the number of images and labels\n",
        "* Visualize some numbers"
      ],
      "metadata": {
        "id": "zzuSwdtsO9wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training samples\n",
        "train[\"features\"].shape[0], train[\"labels\"].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWBVWGDSPy74",
        "outputId": "d02e7889-145e-4e6a-f868-6bf2ac3dea06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of test samples\n",
        "test[\"features\"].shape[0], test[\"labels\"].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckmKtpRAQGPu",
        "outputId": "a97ea390-9412-4af8-cc36-d6e1ccba08fa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into separate train and test variables\n",
        "X_train = train[\"features\"]\n",
        "y_train = train[\"labels\"]\n",
        "\n",
        "X_test = test[\"features\"]\n",
        "y_test = test[\"labels\"]"
      ],
      "metadata": {
        "id": "FPC1R0LyQgKK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see some attributes of the data\n",
        "X_train[0].ndim, X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_IeGlb1RPB6",
        "outputId": "e189d8a7-cbb6-4867-ee12-4e8445902582"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, (28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# observing the data\n",
        "# X_train[0]\n",
        "# commented this to avoid scorlling"
      ],
      "metadata": {
        "id": "CmSIQNzwRcR5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the data\n",
        "\n",
        "It didn't really say anything. We must plot it using matplotlib since the values that are in the form of array is the value of grayscale between the value of Black and White."
      ],
      "metadata": {
        "id": "R4bM7yKER6eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qms5Qd4_SetZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(index):\n",
        "  image = X_train[index].squeeze()\n",
        "  plt.title(f\"Index {index} Label: {y_train[index]}\")\n",
        "  plt.imshow(image, cmap=plt.cm.gray_r)"
      ],
      "metadata": {
        "id": "Pi21HW7qSjuI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "C-WJsfXGS8eT",
        "outputId": "916bed22-3721-4485-a0b1-d2e8722b02ab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "JFK_osqLYf6g",
        "outputId": "21725793-147b-45b6-d850-299124f12c3e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's identify how many labels we have in our training set and their corresponding images."
      ],
      "metadata": {
        "id": "oLuRjAvcY_9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_label_counts = np.unique(y_train, return_counts=True)\n",
        "train_label_df = pd.DataFrame({\"Label\": train_label_counts[0], \"Count\":train_label_counts[1]})\n",
        "train_label_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dmQI4TJsZVdb",
        "outputId": "76dc9806-565f-4fa3-f3f5-a35505fc946a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label  Count\n",
              "0      0   5923\n",
              "1      1   6742\n",
              "2      2   5958\n",
              "3      3   6131\n",
              "4      4   5842\n",
              "5      5   5421\n",
              "6      6   5918\n",
              "7      7   6265\n",
              "8      8   5851\n",
              "9      9   5949"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de80bb86-a7ae-47da-9261-2f0c2d901f2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>6265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>5949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de80bb86-a7ae-47da-9261-2f0c2d901f2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de80bb86-a7ae-47da-9261-2f0c2d901f2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de80bb86-a7ae-47da-9261-2f0c2d901f2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It says, Digit `1` has 6742 samples, `2` has 5958, `3` has 6131 samples and so on... available in training dataset."
      ],
      "metadata": {
        "id": "FVPzOuuQZcLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also by observing the data it looks like that it's already converted into numbers and it's ready to fit in into the model.\n",
        "\n",
        "\n",
        "### Split the data into 3 set (Training, Validation and Test)\n",
        "\n",
        "But as the rule suggests, we must divide the samples into 3 sets, (Training, Validation and Test set).\n",
        "\n",
        "Since we already have the test set available, so we only need to divide the validation test which we split it from training samples.\n",
        "\n",
        "* Training Samples : (48K)\n",
        "* Validation Samples : (12K)\n",
        "* Test Samples : (10K)"
      ],
      "metadata": {
        "id": "AMXkrLoxanRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing train test split library from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=17)"
      ],
      "metadata": {
        "id": "p1pynydlcKx_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the number of splitted data\n",
        "X_train.shape[0], X_valid.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhIfl4CcPYW",
        "outputId": "ff6282d7-4e1a-42ac-f29c-bc63fb4e88d5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 12000)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and now if we compare the lables in each set, after splitting"
      ],
      "metadata": {
        "id": "PCk4x0sXcrSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train, return_counts=True), np.unique(y_valid, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o8o-Cv-c-oc",
        "outputId": "67776f4e-d0af-4bd0-909e-69693a9df904"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              "  array([4719, 5380, 4754, 4956, 4686, 4301, 4734, 5047, 4620, 4803])),\n",
              " (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              "  array([1204, 1362, 1204, 1175, 1156, 1120, 1184, 1218, 1231, 1146])))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data into Batches\n",
        "\n",
        "If we want to train 10K+ samples in one go.. they all might not fit into memory.\n",
        "\n",
        "So that's why we do about 32(this is the batch size) samples at a time. But here I'll consider 128 samples of one batch.\n",
        "\n",
        "**But if all the samples fit into memory then we don't need to convert them into batches.**\n",
        "\n",
        "[Resource](https://www.tensorflow.org/guide/data#reading_input_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Czs-oiq9d3px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size, 128 is a good start\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def create_data_batches(X, y=None, batch_size= BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of X and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle if it's validation data.\n",
        "  Also accepts test data as input\n",
        "  \"\"\"\n",
        "\n",
        "  # If the data is test dataset, we probabily don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating batches for test data....\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) \n",
        "    data_batch = data.batch(batch_size)\n",
        "    return data_batch\n",
        "  # If the data is validation set, we do have labels but we don't shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Create batches for valid data....\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "    data_batch = data.batch(batch_size)\n",
        "    return data_batch\n",
        "  # If the data is training set, we are shuffling the data\n",
        "  else:\n",
        "    print(\"Create batches for training data...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "    # Shuffing the samples\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "    # create data batches\n",
        "    data_batch = data.batch(batch_size)\n",
        "    return data_batch"
      ],
      "metadata": {
        "id": "l2xz2EOcfnXO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "valid_data = create_data_batches(X_valid, y_valid, valid_data=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJdFJ0CEmXUF",
        "outputId": "06f28583-f715-4eeb-ef82-3ad8b55492a1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create batches for training data...\n",
            "Create batches for valid data....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.element_spec, valid_data.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DIx5GADmpaG",
        "outputId": "bd323c6c-67e5-42b6-95ea-2213d00f2b96"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name=None),\n",
              "  TensorSpec(shape=(None,), dtype=tf.uint8, name=None)),\n",
              " (TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name=None),\n",
              "  TensorSpec(shape=(None,), dtype=tf.uint8, name=None)))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YEAH !!!!!!!\n",
        "\n",
        "That's what we wanted. We turned them into tensors and created batches."
      ],
      "metadata": {
        "id": "opW09VhnmuqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling\n",
        "\n",
        "Before we build a model, there are few things we need to define:\n",
        "* Input shape to our model.\n",
        "* Output shape\n",
        "* Choose the right estimator/model to train."
      ],
      "metadata": {
        "id": "fADcEmmRmx5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT SHAPE\n",
        "INPUT_SHAPE = []\n",
        "\n",
        "# Output Shape\n",
        "OUTPUT_SHAPE = []\n",
        "\n",
        "# URL\n",
        "MODEL_URL = \"\""
      ],
      "metadata": {
        "id": "7-UqhjUvnbRm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}