{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oAfdV77pFsDI"
      ],
      "toc_visible": true,
      "mount_file_id": "1bslYAz5kSdbjxBr5EtOXz6lbOhhf3nii",
      "authorship_tag": "ABX9TyMS5LxdE7RrTnzHH+dzf75e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/mnist-digit-recognition/blob/master/recognise_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Recognition\n",
        "\n",
        "Deep Learning model for Handwritten Digit Recognition using TensorFlow and Neural Network Techniques\n",
        "\n",
        "## 1. Problem Definition â›‘\n",
        "\n",
        "Recognise handwritten digit, from a dataset which contains B&W images of each digit written on 28x28 pixel box.\n",
        "\n",
        "## 2. Data \n",
        "\n",
        "The data we're using is officially provided by [The MNIST DATABASE](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "The digits have been sized-normalized and centered in a fixed-sized image.\n",
        "\n",
        "The data is quite preprocessed and well-formatted.\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "Test Error Rate(%) should be lower than 1.0\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data,\n",
        "* We're dealing with images(unstructured data) so it's probably best we use deep learning/transfer learning technique to solve this problem.\n",
        "* There are around a 60,000 examples of training set. \n",
        "* There are around a 10,000 examples of test set."
      ],
      "metadata": {
        "id": "O7o-vJCUoMr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Workspace ready !\n",
        "\n",
        "* Import Tensorflow\n",
        "* Import standard libraries to be used in this experiment"
      ],
      "metadata": {
        "id": "oAfdV77pFsDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "_BIXOY5lq_NE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c567b106-972c-422c-8e54-562d3ff9d97e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standard helper libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7Yern88eF5dX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready\n",
        "\n",
        "The same MNIST dataset is also available in TensorFlow datasets. Thankfully it's splitted into training and test set which enable us to deep dive directly into exploring and visualizing the data.\n",
        "\n",
        "### Import the data\n",
        "\n",
        "Let's import the data using `tensorflow.keras.datasets` library"
      ],
      "metadata": {
        "id": "5BNIeOKtHem7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# The data is splitted into train and test set\n",
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "iKgbFwzSIyIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693b1961-91ec-4d51-8a3c-271237cf8330"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the data\n",
        "\n",
        "Before going further and jumping directly to any step, exploring the data will help us to decide what are the things we need to do with our data,\n",
        "* Find outliers\n",
        "* If we need a preprocessing phase to uniform\n",
        "* Check the number of images and labels\n",
        "* Visualize some numbers"
      ],
      "metadata": {
        "id": "zzuSwdtsO9wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes of training samples\n",
        "train_data.shape, train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWBVWGDSPy74",
        "outputId": "ad711d43-f116-4686-9f98-fb0b8201ee31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes of test samples\n",
        "test_data.shape, test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckmKtpRAQGPu",
        "outputId": "b99bd101-1bb7-4001-e6c6-d28895eac041"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have,\n",
        "* 60000 samples in training data\n",
        "* 10000 samples in test data\n",
        "* input is 28 x 28 grayscale image."
      ],
      "metadata": {
        "id": "3Zx_bH8rL9mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# observing the data\n",
        "# train_data[0]\n",
        "# commented this to avoid scorlling"
      ],
      "metadata": {
        "id": "CmSIQNzwRcR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67a5f26-662f-4d4d-bc9f-5fe807da828b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's in the form of numbers so hardly we can obtain anything by just viewing the numbers in this form, yes we can see that some indexes have 0 as value and in some it's a whole number.\n",
        "\n",
        "But we can plot these and see what these numbers tell."
      ],
      "metadata": {
        "id": "ywhJrDiAHbSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the data\n",
        "\n",
        "We can plot it using matplotlib since the values that shown above are in the form of array of numbers which has shape (1, 28, 28) of single data."
      ],
      "metadata": {
        "id": "R4bM7yKER6eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(data, label, index):\n",
        "  image = data[index].squeeze()\n",
        "  plt.title(f\"Index {index} Label: {label[index]}\")\n",
        "  plt.imshow(image)"
      ],
      "metadata": {
        "id": "Pi21HW7qSjuI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the training image and it's label\n",
        "display_image(train_data, train_labels, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "C-WJsfXGS8eT",
        "outputId": "e60c55e2-1fd8-491a-f2af-af278e95e464"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(train_data, train_labels, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "JFK_osqLYf6g",
        "outputId": "aabbc986-6179-4892-864d-40470eb44c9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's identify how many labels we have in our training set and their corresponding images."
      ],
      "metadata": {
        "id": "oLuRjAvcY_9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_counts = np.unique(train_labels, return_counts=True)\n",
        "train_label_df = pd.DataFrame({\"Label\": train_label_counts[0], \"Count\":train_label_counts[1]})\n",
        "train_label_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dmQI4TJsZVdb",
        "outputId": "f138b276-9eea-4881-e9b2-269dad5cadb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label  Count\n",
              "0      0   5923\n",
              "1      1   6742\n",
              "2      2   5958\n",
              "3      3   6131\n",
              "4      4   5842\n",
              "5      5   5421\n",
              "6      6   5918\n",
              "7      7   6265\n",
              "8      8   5851\n",
              "9      9   5949"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dfa36b1-7473-487d-8806-028e72fb38ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>6265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>5949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dfa36b1-7473-487d-8806-028e72fb38ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dfa36b1-7473-487d-8806-028e72fb38ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dfa36b1-7473-487d-8806-028e72fb38ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It says, Digit `1` has 6742 samples, `2` has 5958, `3` has 6131 samples and so on... available in training dataset.\n",
        "\n",
        "So these are basically our classnames for multi-class classification problem."
      ],
      "metadata": {
        "id": "FVPzOuuQZcLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_label_df[\"Label\"]"
      ],
      "metadata": {
        "id": "yzAYjSVJJ2TQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpxSbo-EKMps",
        "outputId": "5ee6ff21-a1ea-4f7a-dcb2-9c9d9b1cf219"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also by observing the data it looks like that it's already converted into numbers and it's ready to fit in into the model.\n",
        "\n",
        "\n",
        "### Split the data into 3 set (Training, Validation and Test)\n",
        "\n",
        "It's a good practice in order to build our model, we should split the samples into 3 sets, (Training, Validation and Test set).\n",
        "\n",
        "Since we already have the test set available, so we only need to divide the validation test which we split it from training samples.\n",
        "\n",
        "* Training Samples : (48K)\n",
        "* Validation Samples : (12K)\n",
        "* Test Samples : (10K)"
      ],
      "metadata": {
        "id": "AMXkrLoxanRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing train test split library from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_labels, test_size=0.2, random_state=17)"
      ],
      "metadata": {
        "id": "p1pynydlcKx_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the number of splitted data\n",
        "X_train.shape[0], X_valid.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhIfl4CcPYW",
        "outputId": "28fea995-831a-4282-9aa4-921ceba41198"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 12000)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and now if we compare the lables in each set, after splitting"
      ],
      "metadata": {
        "id": "PCk4x0sXcrSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train, return_counts=True), np.unique(y_valid, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o8o-Cv-c-oc",
        "outputId": "2bb65d0b-ad87-4165-960e-5627c96c2831"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              "  array([4719, 5380, 4754, 4956, 4686, 4301, 4734, 5047, 4620, 4803])),\n",
              " (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              "  array([1204, 1362, 1204, 1175, 1156, 1120, 1184, 1218, 1231, 1146])))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have good amount of data to train our model and then validate it using validation set."
      ],
      "metadata": {
        "id": "O2pPfLlXLkf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling\n",
        "\n",
        "We're dealing with Multi-class classification problem, so we might need to take care of few things to build our neural network model,\n",
        "\n",
        "* **Creating a model**: piece together the layers of neural network(using the functional or Sequential API) or import a previously built model(known as transfer learning).\n",
        "  * **Input shape**: We will have to deal with 28 x 28 tensors (height and width of an image)\n",
        "  * **Output shape**: 10, since we have 10 `class_names`(*digits*) to identify\n",
        "  * **Input Activation function**: Since this is non-linear data, se we'll use non-linear activations like reLu, Softmax, Sigmoid\n",
        "  * **Output Activation function**: For classification problems, two common functions are Sigmoid and Softmax, since this is a multi-class so we should use *Softmax*\n",
        "    - **Softmax** : It converts all the output vector into probabilities that the sum of all the probabilities is equal to 1. Kind of argmax, but softer version.\n",
        "* **Compiling a model**: defining how a model's performance should be measured(loss/metrics) as well as defining how it should improve(optimizer).\n",
        "  * **Loss function**: We have to use **CategoricalCrossentropy** or **SparseCategoricalCrossentropy** for multi-class classification problem.\n",
        "    - We will use the later, i.e *SparseCategoricalCrossentropy* since the other one takes encoded inputs, and we are not `one_hot` encoding our training data.\n",
        "  * **Optimizer**: We can choose from SGD or Adam optimizer functions\n",
        "  * **Metrics**: For a classification problem, there are many metrics but by default let's see `accuracy`. How accurate our model is performing.\n",
        "* **Fitting a model**: Letting the model try to find patterns in the data\n",
        "\n",
        "Let's see how it'll go."
      ],
      "metadata": {
        "id": "fADcEmmRmx5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Model"
      ],
      "metadata": {
        "id": "7_s3uxmbv3AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random seed\n",
        "tf.random.set_seed(17)\n",
        "\n",
        "# 1. Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), # input shape define\n",
        "    tf.keras.layers.Dense(4, activation='relu'), # Hidden layer 1 with 4 neurons\n",
        "    tf.keras.layers.Dense(4, activation='relu'), # Hidden layer 2 with 4 neurons\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # Output layer, since shape is 10 so 10 neurons.\n",
        "])\n",
        "\n",
        "# 2. Compiling a model\n",
        "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fitting a model\n",
        "history_1 = model_1.fit(X_train, \n",
        "            y_train, \n",
        "            epochs = 20, \n",
        "            validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7OojIOrO533",
        "outputId": "9d98a747-910f-4e61-9b23-ae8781e04455"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 2.3384 - accuracy: 0.1562 - val_loss: 1.9453 - val_accuracy: 0.2059\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.8860 - accuracy: 0.2173 - val_loss: 1.8386 - val_accuracy: 0.2477\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.7600 - accuracy: 0.2725 - val_loss: 1.6868 - val_accuracy: 0.2825\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.6135 - accuracy: 0.3251 - val_loss: 1.5253 - val_accuracy: 0.3722\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.4784 - accuracy: 0.4133 - val_loss: 1.4424 - val_accuracy: 0.4397\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 1.4167 - accuracy: 0.4407 - val_loss: 1.3916 - val_accuracy: 0.4448\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 1.3721 - accuracy: 0.4601 - val_loss: 1.3720 - val_accuracy: 0.4658\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 1.3425 - accuracy: 0.4754 - val_loss: 1.3312 - val_accuracy: 0.4863\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 1.2969 - accuracy: 0.4995 - val_loss: 1.2765 - val_accuracy: 0.5252\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 1.2533 - accuracy: 0.5306 - val_loss: 1.2365 - val_accuracy: 0.5460\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 1.2093 - accuracy: 0.5590 - val_loss: 1.2066 - val_accuracy: 0.5779\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1694 - accuracy: 0.5823 - val_loss: 1.1780 - val_accuracy: 0.5823\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 1.1281 - accuracy: 0.6071 - val_loss: 1.1206 - val_accuracy: 0.6267\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0986 - accuracy: 0.6305 - val_loss: 1.1200 - val_accuracy: 0.6388\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0876 - accuracy: 0.6413 - val_loss: 1.0836 - val_accuracy: 0.6472\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0664 - accuracy: 0.6527 - val_loss: 1.0932 - val_accuracy: 0.6527\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0562 - accuracy: 0.6570 - val_loss: 1.0657 - val_accuracy: 0.6524\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0517 - accuracy: 0.6582 - val_loss: 1.1165 - val_accuracy: 0.6271\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0455 - accuracy: 0.6596 - val_loss: 1.0473 - val_accuracy: 0.6668\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0410 - accuracy: 0.6630 - val_loss: 1.0768 - val_accuracy: 0.6571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on training samples is **66%** and loss is fairly low. But we still need to improve our model to get better `accuracy`.\n",
        "\n",
        "One more thing we might notice here, `val_accuracy`, these appears in the process of fitting our model, because we passed a parameter i.e `validation_data`.\n",
        "\n",
        "It gives us the idea of how the model performs on validation set during training the model, it gives us the `val_loss` and `val_accuracy`"
      ],
      "metadata": {
        "id": "1gRc_SLzdtqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anyways let's improve our model."
      ],
      "metadata": {
        "id": "2IvThJjVd-1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning our Model\n",
        "\n",
        "A model can tuned/improved in many ways but some common ways we can pass through will be,\n",
        "* Visualize our inputs, *if normalization needed then normalize it*\n",
        "* *Adjust the layers and activation function*\n",
        "* *Tweak optimizer and it's learning rate*\n",
        "* and Many more.."
      ],
      "metadata": {
        "id": "6Be6_N-zfRht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Normalize our inputs\n"
      ],
      "metadata": {
        "id": "UUSv-dEifvSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}